{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f45aedb-dfa3-46f2-a53d-9ab800726e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1332204 entries, 0 to 1332203\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count    Dtype         \n",
      "---  ------                --------------    -----         \n",
      " 0   FLIGHT KEY            1331880 non-null  object        \n",
      " 1   PASSENGERS            1332204 non-null  int64         \n",
      " 2   NOMBRE DE AEROLINEA   1332204 non-null  object        \n",
      " 3   FECHA                 1332204 non-null  datetime64[ns]\n",
      " 4   ORIGEN                1330588 non-null  object        \n",
      " 5   DESTINO               1330588 non-null  object        \n",
      " 6   FLIGHT NO             1331880 non-null  float64       \n",
      " 7   DEPARTUTE LOCAL TIME  1320414 non-null  datetime64[ns]\n",
      " 8   ARRIVAL LOCAL TIME    1332204 non-null  datetime64[ns]\n",
      " 9   SALES                 1313790 non-null  float64       \n",
      " 10  TYPE TRANSACTION      1313790 non-null  object        \n",
      " 11  CATEGORY              1313732 non-null  object        \n",
      " 12  SUPERCATEGORY         1313714 non-null  object        \n",
      " 13  LOST SALES            1332204 non-null  int64         \n",
      " 14  ITEM CODE             1313714 non-null  float64       \n",
      " 15  CURRENCY              1332204 non-null  object        \n",
      " 16  WAREHOUSE             1316105 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(3), int64(2), object(9)\n",
      "memory usage: 172.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "df1 = pd.read_excel(\"datasets/result_hack1.xlsx\")\n",
    "df2 = pd.read_excel(\"datasets/result_hack2.xlsx\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_orig = df.copy()\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01d183a-a4aa-4ccb-90f9-29090f4c5a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401214 entries, 0 to 401213\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   FLIGHT KEY            401214 non-null  object        \n",
      " 1   PASSENGERS            401214 non-null  int64         \n",
      " 2   NOMBRE DE AEROLINEA   401214 non-null  object        \n",
      " 3   FECHA                 401214 non-null  datetime64[ns]\n",
      " 4   ORIGEN                401214 non-null  object        \n",
      " 5   DESTINO               401214 non-null  object        \n",
      " 6   FLIGHT NO             401214 non-null  float64       \n",
      " 7   DEPARTUTE LOCAL TIME  401214 non-null  datetime64[ns]\n",
      " 8   ARRIVAL LOCAL TIME    401214 non-null  datetime64[ns]\n",
      " 9   TYPE TRANSACTION      401214 non-null  object        \n",
      " 10  CATEGORY              401214 non-null  object        \n",
      " 11  SUPERCATEGORY         401214 non-null  object        \n",
      " 12  ITEM CODE             401214 non-null  int64         \n",
      " 13  CURRENCY              401214 non-null  object        \n",
      " 14  WAREHOUSE             401214 non-null  object        \n",
      " 15  SALES                 401214 non-null  int64         \n",
      " 16  LOST SALES            401214 non-null  int64         \n",
      "dtypes: datetime64[ns](3), float64(1), int64(4), object(9)\n",
      "memory usage: 52.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "# Remove entries with null values (oversimplification of a real process)\n",
    "df = df.dropna()\n",
    "\n",
    "df['ITEM CODE'] = df['ITEM CODE'].astype('int64')\n",
    "df['SALES'] = df['SALES'].astype('int64')\n",
    "\n",
    "# In this case, i'm only using SALE type transactions\n",
    "df = df[df['TYPE TRANSACTION'] == 'SALE'].reset_index(drop=True)\n",
    "\n",
    "# Group entries\n",
    "agg_dict = {col: 'first' for col in df.columns if col not in ['SALES', 'LOST SALES']}\n",
    "agg_dict.update({'SALES': 'sum', 'LOST SALES': 'sum'})\n",
    "\n",
    "grouped = (\n",
    "    df.groupby(['FLIGHT KEY', 'CATEGORY'], as_index=False)\n",
    "      .agg(agg_dict)\n",
    ")\n",
    "\n",
    "df = grouped\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7560ed-a8b9-4ee6-9608-304aea2ab0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401214 entries, 0 to 401213\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   FLIGHT KEY                              401214 non-null  object \n",
      " 1   PASSENGERS                              401214 non-null  int64  \n",
      " 2   FLIGHT NO                               401214 non-null  float64\n",
      " 3   ITEM CODE                               401214 non-null  int64  \n",
      " 4   SALES                                   401214 non-null  int64  \n",
      " 5   LOST SALES                              401214 non-null  int64  \n",
      " 6   month_sin                               401214 non-null  float64\n",
      " 7   month_cos                               401214 non-null  float64\n",
      " 8   dow_sin                                 401214 non-null  float64\n",
      " 9   dow_cos                                 401214 non-null  float64\n",
      " 10  DURATION_MIN                            401214 non-null  float64\n",
      " 11  hour_Afternoon                          401214 non-null  int64  \n",
      " 12  hour_EarlyMorning                       401214 non-null  int64  \n",
      " 13  hour_Evening                            401214 non-null  int64  \n",
      " 14  hour_LateNight                          401214 non-null  int64  \n",
      " 15  hour_Morning                            401214 non-null  int64  \n",
      " 16  hour_Noon                               401214 non-null  int64  \n",
      " 17  MEAN_ORIGIN_CONSUPTION                  401214 non-null  float64\n",
      " 18  MEAN_DEST_CONSUPTION                    401214 non-null  float64\n",
      " 19  category_Accessories                    401214 non-null  int64  \n",
      " 20  category_Alcohol                        401214 non-null  int64  \n",
      " 21  category_Cold Drink                     401214 non-null  int64  \n",
      " 22  category_Confectionery                  401214 non-null  int64  \n",
      " 23  category_Fresh Food                     401214 non-null  int64  \n",
      " 24  category_Gents Fragrance                401214 non-null  int64  \n",
      " 25  category_Hot Drink                      401214 non-null  int64  \n",
      " 26  category_Hot Food                       401214 non-null  int64  \n",
      " 27  category_Ladies Fragrance               401214 non-null  int64  \n",
      " 28  category_Logo                           401214 non-null  int64  \n",
      " 29  category_Savoury Snacks                 401214 non-null  int64  \n",
      " 30  category_Skincare & Make-up             401214 non-null  int64  \n",
      " 31  category_Sweet Snacks                   401214 non-null  int64  \n",
      " 32  category_Tobacco                        401214 non-null  int64  \n",
      " 33  category_Tobacco.                       401214 non-null  int64  \n",
      " 34  supercategory_BISTRO                    401214 non-null  int64  \n",
      " 35  supercategory_BOUTIQUE                  401214 non-null  int64  \n",
      " 36  supercategory_DUTY FREE                 401214 non-null  int64  \n",
      " 37  nombre de aerolinea_GateGroup Airlines  401214 non-null  int64  \n",
      " 38  currency_EUR                            401214 non-null  int64  \n",
      "dtypes: float64(8), int64(30), object(1)\n",
      "memory usage: 119.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert date-time columns\n",
    "df['MONTH'] = df['FECHA'].dt.month\n",
    "df['DAY_OF_WEEK'] = df['FECHA'].dt.weekday \n",
    "\n",
    "# Create cyclic variables\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['MONTH']/12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['MONTH']/12)\n",
    "df['dow_sin'] = np.sin(2 * np.pi * df['DAY_OF_WEEK']/7)\n",
    "df['dow_cos'] = np.cos(2 * np.pi * df['DAY_OF_WEEK']/7)\n",
    "\n",
    "df['DURATION_MIN'] = (df['ARRIVAL LOCAL TIME'] - df['DEPARTUTE LOCAL TIME']).dt.total_seconds() / 60 \n",
    "\n",
    "# Extracting hour\n",
    "df['HOUR'] = df['DEPARTUTE LOCAL TIME'].dt.hour\n",
    "\n",
    "def hour_slot(hour):\n",
    "    if 0 <= hour <= 5:\n",
    "        return 'EarlyMorning'\n",
    "    elif 6 <= hour <= 11:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour <= 13:\n",
    "        return 'Noon'\n",
    "    elif 14 <= hour <= 17:\n",
    "        return 'Afternoon'\n",
    "    elif 18 <= hour <= 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'LateNight'\n",
    "\n",
    "df['HOUR_SLOT'] = df['HOUR'].apply(hour_slot)\n",
    "# One-hot encoding\n",
    "df = pd.get_dummies(df, columns=['HOUR_SLOT'], prefix='hour', dtype=int)\n",
    "\n",
    "# Drop original datetime columns\n",
    "drop_cols = ['FECHA', 'DEPARTUTE LOCAL TIME', 'ARRIVAL LOCAL TIME', 'MONTH', 'DAY_OF_WEEK', 'HOUR', 'TYPE TRANSACTION']\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "######################################\n",
    "# In order to use properly the origin and destination info, we obtain the mean consuming of that city\n",
    "# Obtain total sales per flight\n",
    "flight_sales = df.groupby('FLIGHT KEY')['SALES'].sum().reset_index().rename(columns={'SALES': 'TOTAL_SALES'})\n",
    "\n",
    "# Calculate global mean\n",
    "df = df.merge(flight_sales, on='FLIGHT KEY', how='left')\n",
    "global_mean = df['TOTAL_SALES'].mean()\n",
    "\n",
    "# Target encoding function\n",
    "def target_encode_smooth(df, col, target, m=5):\n",
    "    \"\"\"\n",
    "    df: DataFrame\n",
    "    col: column to modify\n",
    "    target: target column\n",
    "    m: smoothing factor\n",
    "    \"\"\"\n",
    "    agg = df.groupby(col)[target].agg(['mean', 'count'])\n",
    "    # smoothing\n",
    "    agg['encoded'] = (agg['mean'] * agg['count'] + global_mean * m) / (agg['count'] + m)\n",
    "    return agg['encoded']\n",
    "\n",
    "origin_encoding = target_encode_smooth(df, 'ORIGEN', 'TOTAL_SALES', m=5)\n",
    "dest_encoding   = target_encode_smooth(df, 'DESTINO', 'TOTAL_SALES', m=5)\n",
    "\n",
    "df['MEAN_ORIGIN_CONSUPTION'] = df['ORIGEN'].map(origin_encoding)\n",
    "df['MEAN_DEST_CONSUPTION'] = df['DESTINO'].map(dest_encoding)\n",
    "\n",
    "df = df.drop(columns=['ORIGEN', 'DESTINO', 'TOTAL_SALES', 'WAREHOUSE'])\n",
    "######################################\n",
    "\n",
    "# Convert categorical variables into binary\n",
    "categorical_cols = ['CATEGORY','SUPERCATEGORY', 'NOMBRE DE AEROLINEA', 'CURRENCY']\n",
    "df = pd.get_dummies(df, columns=categorical_cols, prefix=[c.lower() for c in categorical_cols], dtype=int)\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c72f3bc4-3afb-4295-a835-cd9cb794f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save product code\n",
    "df_ids = df[['ITEM CODE']].copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6dd9b9-c32f-4fe7-b485-6a363858dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and independient variables\n",
    "X = df.drop(columns=['FLIGHT KEY', 'FLIGHT NO'])\n",
    "X.to_csv('models/data.csv',index=False)\n",
    "X = df.drop(columns=['ITEM CODE', 'SALES'])\n",
    "y = df['SALES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba255bcd-13c6-43f2-b839-07325b648f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLIGHT KEY</th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>FLIGHT NO</th>\n",
       "      <th>LOST SALES</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>DURATION_MIN</th>\n",
       "      <th>hour_Afternoon</th>\n",
       "      <th>...</th>\n",
       "      <th>category_Savoury Snacks</th>\n",
       "      <th>category_Skincare &amp; Make-up</th>\n",
       "      <th>category_Sweet Snacks</th>\n",
       "      <th>category_Tobacco</th>\n",
       "      <th>category_Tobacco.</th>\n",
       "      <th>supercategory_BISTRO</th>\n",
       "      <th>supercategory_BOUTIQUE</th>\n",
       "      <th>supercategory_DUTY FREE</th>\n",
       "      <th>nombre de aerolinea_GateGroup Airlines</th>\n",
       "      <th>currency_EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>GGALISMA131520250404</td>\n",
       "      <td>-1.054679</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.934014</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.583000</td>\n",
       "      <td>-1.242938</td>\n",
       "      <td>-0.316044</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154772</th>\n",
       "      <td>GGALISLG134120250524</td>\n",
       "      <td>-0.335321</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.368652</td>\n",
       "      <td>-0.841812</td>\n",
       "      <td>-1.350738</td>\n",
       "      <td>-0.285794</td>\n",
       "      <td>-0.343533</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130296</th>\n",
       "      <td>GGALISFC84120250113</td>\n",
       "      <td>-0.452768</td>\n",
       "      <td>841.0</td>\n",
       "      <td>0.407183</td>\n",
       "      <td>0.368652</td>\n",
       "      <td>1.889114</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>1.438919</td>\n",
       "      <td>-0.144241</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191633</th>\n",
       "      <td>GGALISOR44320250519</td>\n",
       "      <td>0.560206</td>\n",
       "      <td>443.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.368652</td>\n",
       "      <td>-0.841812</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>1.438919</td>\n",
       "      <td>-0.235870</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129776</th>\n",
       "      <td>GGALISFC83920250614</td>\n",
       "      <td>-0.731702</td>\n",
       "      <td>839.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>-0.403646</td>\n",
       "      <td>-1.053050</td>\n",
       "      <td>-1.350738</td>\n",
       "      <td>-0.285794</td>\n",
       "      <td>-0.174021</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83244</th>\n",
       "      <td>GGALGWLI134020250806</td>\n",
       "      <td>-0.790425</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>-1.741306</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>1.416091</td>\n",
       "      <td>-0.285794</td>\n",
       "      <td>-0.350405</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23973</th>\n",
       "      <td>GGABIOAC703320250712</td>\n",
       "      <td>0.251909</td>\n",
       "      <td>7033.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>-1.175945</td>\n",
       "      <td>-0.841812</td>\n",
       "      <td>-1.350738</td>\n",
       "      <td>-0.285794</td>\n",
       "      <td>-0.329789</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167761</th>\n",
       "      <td>GGALISLY47920250821</td>\n",
       "      <td>-0.966595</td>\n",
       "      <td>479.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>-1.741306</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>0.648354</td>\n",
       "      <td>-1.242938</td>\n",
       "      <td>-0.249614</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329074</th>\n",
       "      <td>GGANCELI48820250413</td>\n",
       "      <td>-1.348295</td>\n",
       "      <td>488.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.934014</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-1.076735</td>\n",
       "      <td>0.907745</td>\n",
       "      <td>2.845129</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128142</th>\n",
       "      <td>GGALISFC83720250425</td>\n",
       "      <td>0.295952</td>\n",
       "      <td>837.0</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.934014</td>\n",
       "      <td>-0.264699</td>\n",
       "      <td>-0.583000</td>\n",
       "      <td>-1.242938</td>\n",
       "      <td>-0.153404</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FLIGHT KEY  PASSENGERS  FLIGHT NO  LOST SALES  month_sin  \\\n",
       "170883  GGALISMA131520250404   -1.054679     1315.0   -0.072747   0.934014   \n",
       "154772  GGALISLG134120250524   -0.335321     1341.0   -0.072747   0.368652   \n",
       "130296   GGALISFC84120250113   -0.452768      841.0    0.407183   0.368652   \n",
       "191633   GGALISOR44320250519    0.560206      443.0   -0.072747   0.368652   \n",
       "129776   GGALISFC83920250614   -0.731702      839.0   -0.072747  -0.403646   \n",
       "83244   GGALGWLI134020250806   -0.790425     1340.0   -0.072747  -1.741306   \n",
       "23973   GGABIOAC703320250712    0.251909     7033.0   -0.072747  -1.175945   \n",
       "167761   GGALISLY47920250821   -0.966595      479.0   -0.072747  -1.741306   \n",
       "329074   GGANCELI48820250413   -1.348295      488.0   -0.072747   0.934014   \n",
       "128142   GGALISFC83720250425    0.295952      837.0   -0.072747   0.934014   \n",
       "\n",
       "        month_cos   dow_sin   dow_cos  DURATION_MIN  hour_Afternoon  ...  \\\n",
       "170883  -0.264699 -0.583000 -1.242938     -0.316044               0  ...   \n",
       "154772  -0.841812 -1.350738 -0.285794     -0.343533               0  ...   \n",
       "130296   1.889114  0.032677  1.438919     -0.144241               1  ...   \n",
       "191633  -0.841812  0.032677  1.438919     -0.235870               1  ...   \n",
       "129776  -1.053050 -1.350738 -0.285794     -0.174021               0  ...   \n",
       "83244   -0.264699  1.416091 -0.285794     -0.350405               0  ...   \n",
       "23973   -0.841812 -1.350738 -0.285794     -0.329789               0  ...   \n",
       "167761  -0.264699  0.648354 -1.242938     -0.249614               0  ...   \n",
       "329074  -0.264699 -1.076735  0.907745      2.845129               0  ...   \n",
       "128142  -0.264699 -0.583000 -1.242938     -0.153404               0  ...   \n",
       "\n",
       "        category_Savoury Snacks  category_Skincare & Make-up  \\\n",
       "170883                        0                            0   \n",
       "154772                        0                            0   \n",
       "130296                        0                            0   \n",
       "191633                        0                            0   \n",
       "129776                        0                            0   \n",
       "83244                         0                            0   \n",
       "23973                         0                            0   \n",
       "167761                        1                            0   \n",
       "329074                        0                            0   \n",
       "128142                        1                            0   \n",
       "\n",
       "        category_Sweet Snacks  category_Tobacco  category_Tobacco.  \\\n",
       "170883                      0                 0                  0   \n",
       "154772                      0                 0                  0   \n",
       "130296                      0                 0                  0   \n",
       "191633                      0                 0                  0   \n",
       "129776                      1                 0                  0   \n",
       "83244                       0                 0                  0   \n",
       "23973                       0                 0                  0   \n",
       "167761                      0                 0                  0   \n",
       "329074                      0                 0                  0   \n",
       "128142                      0                 0                  0   \n",
       "\n",
       "        supercategory_BISTRO  supercategory_BOUTIQUE  supercategory_DUTY FREE  \\\n",
       "170883                     1                       0                        0   \n",
       "154772                     1                       0                        0   \n",
       "130296                     1                       0                        0   \n",
       "191633                     1                       0                        0   \n",
       "129776                     1                       0                        0   \n",
       "83244                      1                       0                        0   \n",
       "23973                      1                       0                        0   \n",
       "167761                     1                       0                        0   \n",
       "329074                     1                       0                        0   \n",
       "128142                     1                       0                        0   \n",
       "\n",
       "        nombre de aerolinea_GateGroup Airlines  currency_EUR  \n",
       "170883                                       1             1  \n",
       "154772                                       1             1  \n",
       "130296                                       1             1  \n",
       "191633                                       1             1  \n",
       "129776                                       1             1  \n",
       "83244                                        1             1  \n",
       "23973                                        1             1  \n",
       "167761                                       1             1  \n",
       "329074                                       1             1  \n",
       "128142                                       1             1  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, shuffle=True, random_state=42)\n",
    "\n",
    "numerical_columns = ['PASSENGERS','DURATION_MIN','MEAN_ORIGIN_CONSUPTION','MEAN_DEST_CONSUPTION', 'month_sin', 'month_cos', 'dow_sin', 'dow_cos', 'LOST SALES']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.fit_transform(X_test[numerical_columns])\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bc4b45-56a4-4db3-b715-3a8d79242dbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'GGALISMA131520250404'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_66451/3637743992.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m mlp = MLPRegressor(hidden_layer_sizes=(\u001b[32m69\u001b[39m,), validation_fraction=\u001b[32m0.15\u001b[39m, max_iter=\u001b[32m1000\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mlp.fit(X_train, y_train)\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    845\u001b[39m         -------\n\u001b[32m    846\u001b[39m         self : object\n\u001b[32m    847\u001b[39m             Returns a trained MLP model.\n\u001b[32m    848\u001b[39m         \"\"\"\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._fit(X, y, sample_weight=sample_weight, incremental=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight, incremental)\u001b[39m\n\u001b[32m    469\u001b[39m         first_pass = not hasattr(self, \"coefs_\") or (\n\u001b[32m    470\u001b[39m             \u001b[38;5;28;01mnot\u001b[39;00m self.warm_start \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m incremental\n\u001b[32m    471\u001b[39m         )\n\u001b[32m    472\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m         X, y = self._validate_input(X, y, incremental, reset=first_pass)\n\u001b[32m    474\u001b[39m         n_samples, n_features = X.shape\n\u001b[32m    475\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    476\u001b[39m             sample_weight = _check_sample_weight(sample_weight, X)\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, incremental, reset)\u001b[39m\n\u001b[32m   1759\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _validate_input(self, X, y, incremental, reset):\n\u001b[32m-> \u001b[39m\u001b[32m1760\u001b[39m         X, y = validate_data(\n\u001b[32m   1761\u001b[39m             self,\n\u001b[32m   1762\u001b[39m             X,\n\u001b[32m   1763\u001b[39m             y,\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/Documents/HackMTY/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'GGALISMA131520250404'"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(69,), validation_fraction=0.15, max_iter=1000)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e30b4-f031-48d0-bb3b-0199b53c89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "prediction = mlp.predict(X_test)\n",
    "score = mlp.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(f\"Score: {score}\")\n",
    "print(f\"Mean Square Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Square Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026b2d2-25c6-40d5-9991-9149f2c349b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a8f3d-9ee4-4f28-a209-81f6cf090d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "score2 = rf.score(X_test, y_test)\n",
    "mse2 = mean_squared_error(y_test, prediction)\n",
    "rmse2 = np.sqrt(mse2)\n",
    "mae2 = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "# Results\n",
    "print(f\"R Score: {score2:.4f}\")\n",
    "print(f\"Mean Square Error: {mse2:.4f}\")\n",
    "print(f\"Root Mean Square Error: {rmse2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026d630-996d-4bfb-a4b4-ba63f61efb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "from lightgbm import LGBMRegressor\n",
    "gb = LGBMRegressor(random_state=42)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97492105-ba49-4739-8e49-3830c9daa3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = gb.predict(X_test)\n",
    "\n",
    "score3 = gb.score(X_test, y_test)\n",
    "mse3 = mean_squared_error(y_test, prediction)\n",
    "rmse3 = np.sqrt(mse3)\n",
    "mae3 = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(f\"Score: {score3}\")\n",
    "print(f\"Mean Square Error: {mse3}\")\n",
    "print(f\"Mean Absolute Error: {mae3}\")\n",
    "print(f\"Root Mean Square Error: {rmse3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a54276-5e5b-4777-8c47-9bb088500d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Gradient Boosting Regressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lgbm = LGBMRegressor(random_state=42, verbose=-1)\n",
    "\n",
    "# DDefining a rangge of hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 800, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [8, 12, 15],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,           \n",
    "    scoring='r2',\n",
    "    cv=3,               \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = search.best_estimator_\n",
    "print(\"Best params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9c97f-5a17-47e5-adb6-08cc6dcf25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "score4 = best_model.score(X_test, y_test)\n",
    "mse4 = mean_squared_error(y_test, prediction)\n",
    "rmse4 = np.sqrt(mse3)\n",
    "mae4 = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(f\"Score: {score4}\")\n",
    "print(f\"Mean Square Error: {mse4}\")\n",
    "print(f\"Mean Absolute Error: {mae4}\")\n",
    "print(f\"Root Mean Square Error: {rmse4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0956f66-3126-45d6-9af1-e02667701f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the scaler\n",
    "joblib.dump(best_model, 'models/model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bdb10-0ced-452f-9ece-c3c080cd735e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816b6d0-eb00-4e54-8722-4ead71604d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
